{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adce92be-bb8f-42e0-accf-7f35defb4d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, RidgeCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,root_mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import itertools\n",
    "\n",
    "from utils import clean_data\n",
    "from utils import split_trajectories\n",
    "from utils import replicate_initial_position_by_block\n",
    "from utils import get_n_trajectories\n",
    "from utils import plot_y_yhat\n",
    "from utils import add_three_body_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd647509-a10c-4eba-8dc2-19918fe365b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/X_train.csv')\n",
    "test =  pd.read_csv('../data/X_test.csv')\n",
    "sample_submission = pd.read_csv('../data/sample_submission.csv')#This is a file with random numbers as predictions\n",
    "                                                                #dans le futur fichier résultat ne pas mettre l'index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1e14311-bc70-4579-9632-384a718926df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned=clean_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44908190-b7c7-4f32-b3a2-094c69ae0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_after_split, validation_after_split, test_after_split = split_trajectories(train_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "339d8f03-1ace-453b-b96d-5a5c6c9aab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_entry=replicate_initial_position_by_block(train_after_split)\n",
    "validation_entry=replicate_initial_position_by_block(validation_after_split)\n",
    "test_entry=replicate_initial_position_by_block(test_after_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "125356f0-3598-484a-bf92-84dbdada9416",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enriched = add_three_body_features(train_entry)\n",
    "X_val_enriched   = add_three_body_features(validation_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ebd3b53-4aec-45d7-96db-473a8ea4da1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1, RMSE = 1.17407\n",
      "k = 2, RMSE = 1.15334\n",
      "k = 3, RMSE = 1.15500\n",
      "k = 5, RMSE = 1.12546\n",
      "k = 7, RMSE = 1.06433\n",
      "k = 10, RMSE = 1.00568\n",
      "k = 12, RMSE = 0.97880\n",
      "k = 15, RMSE = 0.94887\n",
      "\n",
      "✅ Meilleur k sur validation : 15 avec RMSE = 0.9488651324055886\n"
     ]
    }
   ],
   "source": [
    "input_cols_enriched = [\n",
    "    't',\n",
    "    'x_1', 'y_1',\n",
    "    'x_2', 'y_2',\n",
    "    #'x_3', 'y_3',\n",
    "    #'r_12', 'r_13', 'r_23',\n",
    "    #'inv_r_12', 'inv_r_13', 'inv_r_23',\n",
    "    #'r12_over_r13', 'r12_over_r23', 'r13_over_r23',\n",
    "    'triangle_area',\n",
    "    #'angle_1','angle_2','angle_3',\n",
    "    #'d1_cm','d2_cm','d3_cm',\n",
    "    #'Lz'\n",
    "]\n",
    "\n",
    "X_train_enriched_selected = X_train_enriched[input_cols_enriched]\n",
    "X_val_enriched_selected   = X_val_enriched[input_cols_enriched]\n",
    "\n",
    "# Targets\n",
    "target_cols = ['x_1','y_1','x_2','y_2','x_3','y_3']\n",
    "y_train = train_after_split[target_cols].copy()\n",
    "y_val   = validation_after_split[target_cols].copy()\n",
    "\n",
    "# Standardisation\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train_enriched_selected)\n",
    "X_val_scaled   = scaler_X.transform(X_val_enriched_selected)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_val_scaled   = scaler_y.transform(y_val)\n",
    "\n",
    "# Valeurs de k à tester\n",
    "k_values = [1,2,3,5,7,10,12,15]\n",
    "\n",
    "results = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsRegressor(n_neighbors=k, weights='distance')\n",
    "    knn.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "    y_val_pred_scaled = knn.predict(X_val_scaled)\n",
    "    y_val_pred = scaler_y.inverse_transform(y_val_pred_scaled)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    results.append({'k': k, 'rmse': rmse})\n",
    "    print(f\"k = {k}, RMSE = {rmse:.5f}\")\n",
    "\n",
    "# Meilleur k\n",
    "best_result = min(results, key=lambda x: x['rmse'])\n",
    "print(\"\\n✅ Meilleur k sur validation :\", best_result['k'], \"avec RMSE =\", best_result['rmse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9059b373-275e-43d3-b34c-754f392b6b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Tester combinaison de variable\n",
    "\n",
    "Les plus intéressantes après test 4,5,(4,5)\n",
    "groupes = {\n",
    "    0: ['t', 'x_1', 'y_1', 'x_2', 'y_2'],  # toujours présents\n",
    "    1: ['r_12', 'r_13', 'r_23'],\n",
    "    2: ['inv_r_12', 'inv_r_13', 'inv_r_23'],\n",
    "    3: ['r12_over_r13', 'r12_over_r23', 'r13_over_r23'],\n",
    "    4: ['triangle_area'],\n",
    "    5: ['d1_cm', 'd2_cm', 'd3_cm']\n",
    "}\n",
    "\n",
    "# Combinaisons possibles des groupes 1 à 5, jusqu'à taille 3\n",
    "groupes_optionnels = [1, 2, 3, 4, 5]\n",
    "combinaisons = []\n",
    "for r in range(0, min(len(groupes_optionnels), 2)+1):  # 0 à 3 groupes choisis\n",
    "    for subset in itertools.combinations(groupes_optionnels, r):\n",
    "        combinaisons.append(subset)\n",
    "\n",
    "print(f\"Nombre total de combinaisons testées (max 3 groupes) : {len(combinaisons)}\")\n",
    "\n",
    "# Targets\n",
    "target_cols = ['x_1','y_1','x_2','y_2','x_3','y_3']\n",
    "y_train = train_after_split[target_cols].copy()\n",
    "y_val   = validation_after_split[target_cols].copy()\n",
    "\n",
    "# Valeurs de k à tester\n",
    "k_values = [15,20]\n",
    "\n",
    "results = []\n",
    "\n",
    "for combo in combinaisons:\n",
    "    # Construire la liste des features à utiliser\n",
    "    features = groupes[0].copy()  # toujours présents\n",
    "    for g in combo:\n",
    "        features += groupes[g]\n",
    "\n",
    "    # Sélection des features\n",
    "    X_train_sel = X_train_enriched[features]\n",
    "    X_val_sel   = X_val_enriched[features]\n",
    "\n",
    "    # Standardisation\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train_sel)\n",
    "    X_val_scaled   = scaler_X.transform(X_val_sel)\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "    y_val_scaled   = scaler_y.transform(y_val)\n",
    "\n",
    "    # Boucle sur les valeurs de k\n",
    "    for k in k_values:\n",
    "        knn = KNeighborsRegressor(n_neighbors=k, weights='distance')\n",
    "        knn.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "        y_val_pred_scaled = knn.predict(X_val_scaled)\n",
    "        y_val_pred = scaler_y.inverse_transform(y_val_pred_scaled)\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "        results.append({\n",
    "            'groupes': combo,\n",
    "            'features': features,\n",
    "            'k': k,\n",
    "            'rmse': rmse\n",
    "        })\n",
    "        print(f\"Groupes {combo}, k={k}, RMSE={rmse:.5f}\")\n",
    "\n",
    "# Trouver le meilleur résultat\n",
    "best_result = min(results, key=lambda x: x['rmse'])\n",
    "print(\"\\n✅ Meilleur modèle :\")\n",
    "print(f\"Groupes = {best_result['groupes']}, k = {best_result['k']}, RMSE = {best_result['rmse']:.5f}\")\n",
    "print(f\"Features utilisées : {best_result['features']}\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad46fc1-54fd-40ab-b063-971af87c4e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enriched = add_three_body_features(train_entry)\n",
    "\n",
    "X_test = test[['t','x0_1','y0_1','x0_2','y0_2','x0_3','y0_3']].copy()\n",
    "X_test.columns = ['t','x_1','y_1','x_2','y_2','x_3','y_3'] \n",
    "X_test_enriched  = add_three_body_features(X_test)\n",
    "\n",
    "# Colonnes à utiliser\n",
    "input_cols_enriched = [\n",
    "    't',\n",
    "    'x_1', 'y_1',\n",
    "    'x_2', 'y_2',\n",
    "    #'x_3', 'y_3',\n",
    "    #'r_12', 'r_13', 'r_23',\n",
    "    #'inv_r_12', 'inv_r_13', 'inv_r_23',\n",
    "    #'r12_over_r13', 'r12_over_r23', 'r13_over_r23',\n",
    "    'triangle_area',\n",
    "    #'angle_1','angle_2','angle_3',\n",
    "    #'d1_cm','d2_cm','d3_cm',\n",
    "    #'Lz'\n",
    "]\n",
    "\n",
    "X_train_enriched_selected = X_train_enriched[input_cols_enriched]\n",
    "X_test_enriched_selected  = X_test_enriched[input_cols_enriched]\n",
    "\n",
    "# Targets\n",
    "target_cols = ['x_1', 'y_1', 'x_2', 'y_2', 'x_3', 'y_3']\n",
    "y_train = train_after_split[target_cols].copy()\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train_enriched_selected)\n",
    "X_test_scaled  = scaler_X.transform(X_test_enriched_selected)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "\n",
    "knn_model = KNeighborsRegressor(n_neighbors=50, weights='distance')\n",
    "knn_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "y_test_pred_scaled = knn_model.predict(X_test_scaled)\n",
    "y_test_pred = scaler_y.inverse_transform(y_test_pred_scaled)\n",
    "\n",
    "output_df = pd.DataFrame(y_test_pred, columns=target_cols)\n",
    "output_df.insert(0, 'Id', np.arange(len(output_df)))\n",
    "\n",
    "output_df.to_csv('knn_submission.csv', index=False)\n",
    "print(\"✅ Fichier 'knn_submission.csv' généré avec succès !\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
